---
title: "p8105_hw5_wch2124"
output: html_document
date: '2023-11-13'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## problem 1 (0 points)
```{r}
## solution reviewed in class 
```

## problem 2 

```{r}
## load packages 
library(tidyverse)
library(rvest)
```

Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time:

```{r}
##Start with a dataframe containing all file names; the list.files function will help

long_data = list.files("./data", pattern = ".csv", all.files = FALSE, 
full.names = FALSE)

#long_data
```

```{r}
## Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe and Tidy the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary

tidy_data = data.frame(participants = long_data) |> 
  mutate(file_contents = map(participants, ~read.csv(file.path("./data", .)))) |>  
  separate(participants, into = c("control", "subject_id")) |>  
  unnest(file_contents) |> 
  mutate(control = recode(control, `con` = "control", `exp` = "experiment")) |>
  pivot_longer(week_1:week_8,
               names_to = "week",
               names_prefix = "week_",
               values_to = "observation")
```

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups:

The plot shows a clear distinction between the control and experiment groups. Overall, subjects in the control group exhibited less observations over the course of 8 weeks than the subjects experiment group.The greatest number of observations in the control group was about 4, and the greatest number of observations in the experiment group was about 7.5. Very few subjects in the experiment group had less than zero observations recorded, whereas a great number of subjects in the control group had less than zero observations.

```{r}
tidy_data |> 
  ggplot(aes(x = week, y = observation)) +
  geom_line(aes(group = subject_id, color = subject_id)) +
  labs(
    title = "Observations on Subjects Over Time",
    x = "Week",
    y = "Observations") + facet_grid(. ~ control)

 
```

## problem 3 

First set the following design elements:

```{r}
set.seed(12345)
```

Set μ=0, Generate 5000 datasets from the model:

```{r}
sim_data_func = function(mu) {
  sim_data = tibble(rnorm(n = 30, mean = mu, sd = 5))
  
  sim_data |> 
    t.test() |> 
    broom::tidy() |> 
    select(estimate, p.value)

}

sim_results = 
  expand_grid(
    mu = 0,
    iter = 1:5000) |> 
  mutate(estimate_df = map(mu, sim_data_func)) |> 
  unnest(estimate_df)
```

Repeat the above for μ={1,2,3,4,5,6}:

```{r}
sim_results2 =
  expand_grid(
    mu = 1:6,
    iter = 1:5000) |> 
  mutate(estimate_df = map(mu, sim_data_func)) |> 
  unnest(estimate_df)
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power:

```{r}
sim_results2 |> 
  filter(p.value < 0.05) |> 
  group_by(mu) |> 
  summarise(power = n()/5000) |> 
  ggplot(aes(x = mu, y = power)) +
  geom_point() + labs(title = "Association Between Effect Size and Power") +
  geom_smooth()  
```

Make a plot showing the average estimate of μ̂ on the y axis and the true value of μ on the x axis:

```{r}
sim_results2 |> 
  group_by(mu) |> 
  summarise(mu_estimate = mean(estimate)) |> 
  ggplot(aes(x = mu, y = mu_estimate)) +
  geom_point() + labs(title = "Comparing Estimates of Mu") +
  geom_smooth()  
  
```

Make a second plot the average estimate of μ̂ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.

```{r}

sim_results2 |> 
  group_by(mu) |> 
  filter(p.value < 0.05) |> 
  summarise(mu_estimate = mean(estimate)) |> 
  ggplot(aes(x = mu, y = mu_estimate)) +
  geom_point() + labs(title = "Average Estimate of mu in Samples Where the Null was Rejected") +
  geom_smooth()

```

Is the sample average of μ̂ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?

The sample average of mu across tests for which the null is rejected is equal to the true mean when mu is equal to or greater than 4, and not equal to the true mean when mu is less than 4. This is because of power and effect size: when mu is equal to or greater than 4, power and effect size are large. When mu is less than 4 it is because effect size and power are small. This is illustrated in the first graph, titled "Association Between Effect Size and Power". 